{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOUhi8F8OJ+X07m9hwW4nmW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Shakilkhan24/Playground_DL/blob/main/custom_tool_with_rag_(agent).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "9H6ajysMJF3U"
      },
      "outputs": [],
      "source": [
        "api_key=''"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain\n",
        "!pip install langchain-openai\n",
        "!pip install chromadb"
      ],
      "metadata": {
        "id": "ITV7-G_2JdJB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pydantic.v1 import BaseModel, Field\n",
        "from langchain_community.document_loaders import NotebookLoader\n",
        "loader = NotebookLoader(\n",
        "    \"/content/kaggle-llama-3-8b-unsloth-notebook.ipynb\",\n",
        "    include_outputs=True,\n",
        "    max_output_length=20,\n",
        "    remove_newline=True,\n",
        ")"
      ],
      "metadata": {
        "id": "7xbXXm47KJqU"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pydantic.v1 import validator"
      ],
      "metadata": {
        "id": "kdsRZajNVSkk"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(loader.load()[0].page_content)"
      ],
      "metadata": {
        "id": "f8ZNHZJzK4Ji"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import osqp\n",
        "import chromadb\n",
        "from langchain_community.vectorstores import Chroma\n",
        "from langchain_community.embeddings import OpenAIEmbeddings\n",
        "from langchain_community.chat_models import ChatOpenAI\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_openai import OpenAI\n",
        "from langchain import PromptTemplate\n",
        "\n",
        "chat = ChatOpenAI(temperature=0, openai_api_key=api_key)\n",
        "embedding = OpenAIEmbeddings(openai_api_key=api_key)\n",
        "\n",
        "splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=1000,\n",
        "    chunk_overlap=200,\n",
        " )\n",
        "docs=loader.load()\n",
        "text_chunks = splitter.split_documents(docs)\n",
        "\n",
        "db = Chroma.from_documents(text_chunks, embedding,persist_directory=\"./chroma_db\")"
      ],
      "metadata": {
        "id": "MeNAkpWqK7HH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "local_file_path = \"/content/chroma_db\"\n",
        "files.download(local_file_path)"
      ],
      "metadata": {
        "id": "-SSeh1tQMB4u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "db=db3 = Chroma(persist_directory=\"/content/chroma_db\", embedding_function=embedding)\n",
        "result=db.similarity_search('adding lora adapters')\n",
        "for i in result:\n",
        "  print(i.page_content)\n"
      ],
      "metadata": {
        "id": "ju65y4gXQ1lX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class RAG:\n",
        "  def __init__(self,chroma_path,prompt):\n",
        "    self.prompt=prompt\n",
        "    self.db= Chroma(persist_directory=chroma_path, embedding_function=embedding)\n",
        "  def run(self):\n",
        "    template=\"\"\" Based on the retrieved datas : <context> {retrieved} </context>, answer the following question :<context> {question}\n",
        "    </context> and generate code snippet for better understanding if needed or asked.\n",
        "    \"\"\"\n",
        "    similar_results=self.db.similarity_search(self.prompt)\n",
        "    retrieved_data=' '\n",
        "    for i in similar_results:\n",
        "      retrieved_data+=i.page_content\n",
        "\n",
        "    chat = ChatOpenAI(temperature=0, openai_api_key=api_key)\n",
        "    prompt_template=PromptTemplate.from_template(template)\n",
        "    final_prompt=prompt_template.format(retrieved=retrieved_data,question=self.prompt)\n",
        "    answer=chat.invoke(final_prompt)\n",
        "    return answer\n"
      ],
      "metadata": {
        "id": "OvwvAaeyNZvO"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "r=RAG(chroma_path=\"/content/chroma_db\",prompt='how to add eos token in the case of terminating generation?')\n",
        "answer=r.run()\n",
        "print(answer.content)"
      ],
      "metadata": {
        "id": "H3X49DwqQH3z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.tools import BaseTool, StructuredTool, tool\n",
        "\n",
        "\n",
        "def func(prompt:str):   # another argument is chroma_path:str\n",
        "  r=RAG(chroma_path='/content/chroma_db',prompt=prompt)\n",
        "  result=r.run()\n",
        "  return result\n",
        "\n",
        "class Input(BaseModel):\n",
        "    # chroma_path: str = Field(..., description='Provide a valid Chroma vector database path')\n",
        "    prompt: str = Field(..., description='Provide a string prompt text')\n",
        "\n",
        "    # @validator('chroma_path')\n",
        "    # def validate_chroma_path(cls, chroma_path):\n",
        "    #     if not chroma_path or not chroma_path.endswith('/chroma_db'):\n",
        "    #         raise ValueError('Vector database path must end with: /chroma_db ')\n",
        "    #     return chroma_path\n",
        "\n",
        "retriever_tool = StructuredTool.from_function(\n",
        "    func=func,\n",
        "    name=\"chroma_data_base to answer generation\",\n",
        "    description=\"retrive data from chroma vector database and then based on the retrieved data generating answer through llm invokation\",\n",
        "    args_schema=Input,\n",
        "    return_direct=True,\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "id": "BvfnMD0yNAp0"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(retriever_tool.name)\n",
        "print(retriever_tool.description)\n",
        "print(retriever_tool.args)"
      ],
      "metadata": {
        "id": "QULl7_FiZ1rB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchainhub\n",
        "!pip install langchain-experimental"
      ],
      "metadata": {
        "id": "gVZ-XdRvboXj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain import hub\n",
        "from langchain.agents import Tool, AgentExecutor, create_react_agent\n",
        "prompt = hub.pull('hwchase17/react')\n",
        "\n",
        "tools = [retriever_tool]\n",
        "\n",
        "agent = create_react_agent(chat, tools, prompt)\n",
        "agent_executor = AgentExecutor(\n",
        "    agent=agent,\n",
        "    tools=tools,\n",
        "    verbose=True,\n",
        "    handle_parsing_errors=True,\n",
        "    max_iterations=2\n",
        ")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "lzBTDBjjaAUo"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agent_executor.invoke({'input':'how to load fourbits model? '})"
      ],
      "metadata": {
        "id": "GIRIoBVheJzb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-7gi0WYbjjiQ"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VK68gWtQlKXr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}