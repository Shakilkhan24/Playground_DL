{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO3g4jCw42tz2V5YgVvcIgm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Shakilkhan24/Playground_DL/blob/main/langchain_simple_introductory_pipeline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('I just followed a sample sequential way of langchain chatbot building')\n",
        "print('i did not run on any data or sources , even i did not run the code, Just arranged all together' )\n",
        "print('as if i can work on sequentially later and do powerfull stuffs on each point')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dFRXScSbOMab",
        "outputId": "8c4e1a02-b68c-4870-81fd-302de92fb85a"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I just followed a sample sequential way of langchain chatbot building\n",
            "i did not run on any data or sources , even i did not run the code, Just arranged all together\n",
            "as if i can work on sequentially later and do powerfull stuffs on each point\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## sample pipeline for langchain\n",
        "llm > promt > external sources > retriever > vector_stores > tools (retrieving, web_searching) > agent(tools) > fast_api > prompts_settings for agents_ to run"
      ],
      "metadata": {
        "id": "jLTBd92hONc8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rUH6qVauLMZA"
      },
      "outputs": [],
      "source": [
        "!pip install langchain langchain-openai chromadb tavily\n",
        "\n",
        "from typing import List\n",
        "\n",
        "# for deployment possibly\n",
        "from fastapi import FastAPI\n",
        "# ____________________________________________________________________ #\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_community.document_loaders import WebBaseLoader\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "from langchain_community.vectorstores import FAISS\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "# tool\n",
        "from langchain.tools.retriever import create_retriever_tool\n",
        "from langchain_community.tools.tavily_search import TavilySearchResults\n",
        "# _____________________________________________________________________ #\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain import hub\n",
        "# agent\n",
        "from langchain.agents import create_openai_functions_agent\n",
        "from langchain.agents import AgentExecutor\n",
        "# _____________________________________________________________________ #\n",
        "from langchain.pydantic_v1 import BaseModel, Field\n",
        "from langchain_core.messages import BaseMessage\n",
        "from langserve import add_routes\n",
        "\n",
        "# 1. Load Retriever\n",
        "loader = WebBaseLoader(\"https://docs.smith.langchain.com/overview\")\n",
        "docs = loader.load()\n",
        "text_splitter = RecursiveCharacterTextSplitter()\n",
        "documents = text_splitter.split_documents(docs)\n",
        "embeddings = OpenAIEmbeddings()\n",
        "vector = FAISS.from_documents(documents, embeddings)\n",
        "retriever = vector.as_retriever()\n",
        "\n",
        "# 2. Create Tools\n",
        "retriever_tool = create_retriever_tool(\n",
        "    retriever,\n",
        "    \"langsmith_search\",\n",
        "    \"Search for information about LangSmith. For any questions about LangSmith, you must use this tool!\",\n",
        ")\n",
        "search = TavilySearchResults()\n",
        "tools = [retriever_tool, search]\n",
        "\n",
        "\n",
        "# 3. Create Agent\n",
        "prompt = hub.pull(\"hwchase17/openai-functions-agent\")\n",
        "llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0)\n",
        "agent = create_openai_functions_agent(llm, tools, prompt)\n",
        "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n",
        "\n",
        "\n",
        "# 4. App definition\n",
        "app = FastAPI(\n",
        "  title=\"LangChain Server\",\n",
        "  version=\"1.0\",\n",
        "  description=\"A simple API server using LangChain's Runnable interfaces\",\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "# Deal with prompt templates for retrieving datas from\n",
        "external sources like documents or webpage.\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "ore79hrVPJr3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. AgentExecuter(some input output prompts)\n",
        "\n",
        "class Input(BaseModel):\n",
        "    input: str\n",
        "    chat_history: List[BaseMessage] = Field(\n",
        "        ...,\n",
        "        extra={\"widget\": {\"type\": \"chat\", \"input\": \"location\"}},\n",
        "    )\n",
        "\n",
        "\n",
        "class Output(BaseModel):\n",
        "    output: str\n",
        "\n",
        "add_routes(\n",
        "    app,\n",
        "    agent_executor.with_types(input_type=Input, output_type=Output),\n",
        "    path=\"/agent\",\n",
        ")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    import uvicorn\n",
        "\n",
        "    uvicorn.run(app, host=\"localhost\", port=8000)"
      ],
      "metadata": {
        "id": "PtbHV4tMO_tm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}